{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedLesk: \n",
    "\n",
    "    def __init__(self):\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    def disambiguate(self, word, sentence):       \n",
    "        word_senses = wordnet.synsets(word)\n",
    "        best_sense = word_senses[0]  # Assume that first sense is most freq.\n",
    "        max_overlap = 0\n",
    "        context = set(word_tokenize(sentence))\n",
    "        for sense in word_senses:\n",
    "            signature = self.tokenized_gloss(sense)\n",
    "            overlap = self.compute_overlap(signature, context)            \n",
    "            if overlap > max_overlap:\n",
    "                max_overlap = overlap\n",
    "                best_sense = sense\n",
    "        return best_sense \n",
    "    \n",
    "    def find(self, sentence):\n",
    "        context = set(word_tokenize(sentence))\n",
    "        context = context.difference(self.stopwords)\n",
    "        z=[]\n",
    "        for i in context:            \n",
    "            if len(wordnet.synsets(i))>2:\n",
    "                z.append(i)\n",
    "        return z\n",
    "    \n",
    "    def tokenized_gloss(self, sense):        \n",
    "        tokens = set(word_tokenize(sense.definition()))\n",
    "        for example in sense.examples():\n",
    "            tokens.union(set(word_tokenize(example)))\n",
    "        return tokens\n",
    "\n",
    "    def compute_overlap(self, signature, context):       \n",
    "        sig = signature.difference(self.stopwords)\n",
    "        return len(sig.intersection(context))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=(\"Crickets, are insects somewhat related to grasshoppers and more closely related to katydids or bush crickets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['related', 'Crickets', 'bush', 'crickets', 'closely']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=SimplifiedLesk()\n",
    "z=model.find(s1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "def get_Words():\n",
    "        sentence = utext.get('1.0', \"end\").strip()\n",
    "        \n",
    "        model=SimplifiedLesk()\n",
    "        z=model.find(sentence)       \n",
    "        \n",
    "        AW.config(state='normal') \n",
    "        AW.delete('1.0','end')\n",
    "        AW.insert('1.0', z)\n",
    "        AW.config(state='disabled')\n",
    "\n",
    "def get_sense():\n",
    "        sentence = utext.get('1.0', \"end\").strip()       \n",
    "        word = Word.get('1.0', \"end\").strip()  \n",
    "        \n",
    "        model=SimplifiedLesk()\n",
    "        sense=model.disambiguate(word,sentence)        \n",
    "        \n",
    "        summary.config(state='normal') \n",
    "        summary.delete('1.0','end')\n",
    "        summary.insert('1.0', sense.definition())        \n",
    "\n",
    "        summary.config(state='disabled')\n",
    "        \n",
    "\n",
    "root = tk.Tk()\n",
    "root.title('Word Sense Predictor')\n",
    "root.geometry('1200x600')\n",
    "\n",
    "\n",
    "\n",
    "slabel = tk.Label(root, text='Sense')\n",
    "slabel.pack()\n",
    "summary = tk.Text(root, height=18, width=130)\n",
    "summary.config(state='disabled', bg='#dddddd')\n",
    "summary.pack()\n",
    "\n",
    "ulabel = tk.Label(root, text='sentence')\n",
    "ulabel.pack()\n",
    "utext = tk.Text(root, height=1, width=130)\n",
    "utext.pack()\n",
    "\n",
    "\n",
    "btn1 = tk.Button(root, text='Get_Words', command=get_Words)\n",
    "btn1.pack()\n",
    "\n",
    "wlabel = tk.Label(root, text='Ambiguous words')\n",
    "wlabel.pack()\n",
    "AW= tk.Text(root, height=5, width=65)\n",
    "AW.config(state='disabled', bg='#dddddd')\n",
    "AW.pack()\n",
    "\n",
    "\n",
    "\n",
    "alabel = tk.Label(root, text='Word To be disambiguated')\n",
    "alabel.pack()\n",
    "Word = tk.Text(root, height=1.2, width=20)\n",
    "Word.pack()\n",
    "\n",
    "\n",
    "btn2 = tk.Button(root, text='Get_Sense', command=get_sense)\n",
    "btn2.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
